{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3868936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : torch.Size([7, 512])\n",
      "bias : torch.Size([7])\n",
      "test acc:  tensor(0.8903, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import clip\n",
    "device = torch.device('cuda:0')\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, phase, transform=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        dataset = pd.read_csv(os.path.join('../../data/FERPlus', 'test_new_fer.txt'), sep=' ', header=None)\n",
    "        \n",
    "        name_c = 0\n",
    "        label_c = 1\n",
    "\n",
    "            \n",
    "        self.label = dataset.iloc[:, label_c].values\n",
    "        images_names = dataset.iloc[:, name_c].values\n",
    "        self.aug_func = [flip_image, add_g]\n",
    "        self.file_paths = []\n",
    "        self.clean = True\n",
    "        \n",
    "        for f in images_names:\n",
    "            path = os.path.join('../../data/FERPlus', f)\n",
    "            self.file_paths.append(path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        image = cv2.imread(self.file_paths[idx])\n",
    "        image = image[:, :, ::-1]        \n",
    "        image = self.transform(image)\n",
    "        image1 = transforms.RandomHorizontalFlip(p=1)(image)\n",
    "        return image, label, idx, image1\n",
    "    \n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, n_blocks, channels, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        \n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block=BasicBlock, n_blocks=[2,2,2,2], channels=[64, 128, 256, 512], stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n",
    "    \n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=7, drop_rate=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        res18 = ResNet(block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512], output_dim=1000)\n",
    "        msceleb_model = torch.load('../../checkpoint/resnet18_msceleb.pth')\n",
    "        state_dict = msceleb_model['state_dict']\n",
    "        res18.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])\n",
    "        self.features2 = nn.Sequential(*list(res18.children())[-2:-1])\n",
    "        \n",
    "        fc_in_dim = list(res18.children())[-1].in_features  # original fc layer's in dimention 512\n",
    "        self.fc = nn.Linear(fc_in_dim, num_classes)  # new fc layer 512x7\n",
    "        \n",
    "        self.parm={}\n",
    "        for name,parameters in self.fc.named_parameters():\n",
    "            print(name,':',parameters.size())\n",
    "            self.parm[name]=parameters\n",
    "        \n",
    "    def forward(self, x, clip_model):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        feat = x\n",
    "        ##N 512 7 7\n",
    "        x = self.features2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        fc_weights = self.parm['weight'].cuda()\n",
    "        fc_weights = fc_weights.view(1, 7, 512, 1, 1)\n",
    "        fc_weights = Variable(fc_weights, requires_grad = False)\n",
    "        feat = feat.unsqueeze(1) # N * 1 * C * H * W\n",
    "        hm = feat * fc_weights\n",
    "        hm = hm.sum(2) # N * self.num_labels * H * W\n",
    "        \n",
    "        out = self.fc(x)\n",
    "        return out, hm\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def add_g(image_array, mean=0.0, var=30):\n",
    "    std = var ** 0.5\n",
    "    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n",
    "    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n",
    "    return image_add\n",
    "\n",
    "def flip_image(image_array):\n",
    "    return cv2.flip(image_array, 1)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../../data/raf-basic', help='raf_dataset_path')\n",
    "parser.add_argument('--resnet50_path', type=str, default='../../data/resnet50_ft_weight.pkl', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "parser.add_argument('--w', type=int, default=7, help='width of the attention map')\n",
    "parser.add_argument('--h', type=int, default=7, help='height of the attention map')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='the number of the device')\n",
    "parser.add_argument('--lam', type=float, default=5, help='kl_lambda')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, optimizer, scheduler, device):\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    total_loss = []\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "    \n",
    "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        \n",
    "\n",
    "        output, hm1 = model(imgs1, clip_model)\n",
    "        \n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss1 \n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n",
    "    return acc, running_loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "setup_seed(3407)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.25)) ])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = RafDataset(phase='train', transform=train_transforms)\n",
    "test_dataset = RafDataset(phase='test', transform=eval_transforms)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model()\n",
    "device = torch.device('cuda:{}'.format(args.gpu))\n",
    "model.load_state_dict(torch.load(\"eac_FERPlus.pth\")['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "\n",
    "\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs, x = model(imgs1, clip_model)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "\n",
    "        running_loss += loss\n",
    "        data_num += outputs.size(0)\n",
    "\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    test_acc = correct_sum.float() / float(data_num)\n",
    "    print('test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe42be",
   "metadata": {},
   "source": [
    "### test on AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffc953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : torch.Size([7, 512])\n",
      "bias : torch.Size([7])\n",
      "test acc:  tensor(0.3649, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import clip\n",
    "device = torch.device('cuda:0')\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, phase, transform=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        NAME_COLUMN = 0\n",
    "        LABEL_COLUMN = 1\n",
    "\n",
    "        dataset = pd.read_csv('../../datasets/AffectNet/sota_test7.txt', sep=' ', header=None)\n",
    "\n",
    "        file_names = dataset.iloc[:, NAME_COLUMN].values\n",
    "        self.label = dataset.iloc[:, LABEL_COLUMN].values\n",
    "        self.file_paths = []\n",
    "        for f in file_names:\n",
    "            path = os.path.join('../../AffectNet_sota_Manually_Annotated_Images', f)\n",
    "            self.file_paths.append(path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        img = image[:, :, ::-1]  # BGR to RGB\n",
    "\n",
    "        label = self.label[idx]\n",
    "        if label == 0:\n",
    "            label = 6\n",
    "        elif label == 1:\n",
    "            label = 3\n",
    "        elif label == 2:\n",
    "            label = 4\n",
    "        elif label == 3:\n",
    "            label = 0\n",
    "        elif label == 4:\n",
    "            label = 1\n",
    "        elif label == 5:\n",
    "            label = 2\n",
    "        elif label == 6:\n",
    "            label = 5\n",
    "            \n",
    "        image = self.transform(image)\n",
    "        img1 = transforms.RandomHorizontalFlip(p=1.0)(image)\n",
    "        return image, label, idx, img1 \n",
    "\n",
    "    def get_labels(self):\n",
    "        label = self.label\n",
    "        return label\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, n_blocks, channels, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        \n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block=BasicBlock, n_blocks=[2,2,2,2], channels=[64, 128, 256, 512], stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n",
    "    \n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=7, drop_rate=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        res18 = ResNet(block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512], output_dim=1000)\n",
    "        msceleb_model = torch.load('../../checkpoint/resnet18_msceleb.pth')\n",
    "        state_dict = msceleb_model['state_dict']\n",
    "        res18.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])\n",
    "        self.features2 = nn.Sequential(*list(res18.children())[-2:-1])\n",
    "        \n",
    "        fc_in_dim = list(res18.children())[-1].in_features  # original fc layer's in dimention 512\n",
    "        self.fc = nn.Linear(fc_in_dim, num_classes)  # new fc layer 512x7\n",
    "        \n",
    "        self.parm={}\n",
    "        for name,parameters in self.fc.named_parameters():\n",
    "            print(name,':',parameters.size())\n",
    "            self.parm[name]=parameters\n",
    "        \n",
    "    def forward(self, x, clip_model):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        feat = x\n",
    "        ##N 512 7 7\n",
    "        x = self.features2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        fc_weights = self.parm['weight'].cuda()\n",
    "        fc_weights = fc_weights.view(1, 7, 512, 1, 1)\n",
    "        fc_weights = Variable(fc_weights, requires_grad = False)\n",
    "        feat = feat.unsqueeze(1) # N * 1 * C * H * W\n",
    "        hm = feat * fc_weights\n",
    "        hm = hm.sum(2) # N * self.num_labels * H * W\n",
    "        \n",
    "        out = self.fc(x)\n",
    "        return out, hm\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def add_g(image_array, mean=0.0, var=30):\n",
    "    std = var ** 0.5\n",
    "    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n",
    "    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n",
    "    return image_add\n",
    "\n",
    "def flip_image(image_array):\n",
    "    return cv2.flip(image_array, 1)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../../data/raf-basic', help='raf_dataset_path')\n",
    "parser.add_argument('--resnet50_path', type=str, default='../../data/resnet50_ft_weight.pkl', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "parser.add_argument('--w', type=int, default=7, help='width of the attention map')\n",
    "parser.add_argument('--h', type=int, default=7, help='height of the attention map')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='the number of the device')\n",
    "parser.add_argument('--lam', type=float, default=5, help='kl_lambda')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, optimizer, scheduler, device):\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    total_loss = []\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "    \n",
    "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        \n",
    "\n",
    "        output, hm1 = model(imgs1, clip_model)\n",
    "        \n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss1 \n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n",
    "    return acc, running_loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "setup_seed(3407)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.25)) ])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = RafDataset(phase='train', transform=train_transforms)\n",
    "test_dataset = RafDataset(phase='test', transform=eval_transforms)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model()\n",
    "device = torch.device('cuda:{}'.format(args.gpu))\n",
    "model.load_state_dict(torch.load(\"eac_FERPlus.pth\")['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "\n",
    "\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs, x = model(imgs1, clip_model)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "\n",
    "        running_loss += loss\n",
    "        data_num += outputs.size(0)\n",
    "\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    test_acc = correct_sum.float() / float(data_num)\n",
    "    print('test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc232c",
   "metadata": {},
   "source": [
    "## SFEW2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3821e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : torch.Size([7, 512])\n",
      "bias : torch.Size([7])\n",
      "test acc:  tensor(0.4579, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import clip\n",
    "device = torch.device('cuda:0')\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, phase, transform=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        NAME_COLUMN = 0\n",
    "        LABEL_COLUMN = 1\n",
    "\n",
    "        dataset = pd.read_csv('../SFEW2_label.txt', sep=' ', header=None)\n",
    "\n",
    "        self.file_paths = dataset.iloc[:, NAME_COLUMN].values\n",
    "        self.label = dataset.iloc[:, LABEL_COLUMN].values\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = '../'+self.file_paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        img = image[:, :, ::-1]  # BGR to RGB\n",
    "\n",
    "        label = self.label[idx]\n",
    "        if label == 0:\n",
    "            label = 5\n",
    "        elif label == 1:\n",
    "            label = 2\n",
    "        elif label == 2:\n",
    "            label = 1\n",
    "        elif label == 3:\n",
    "            label = 3\n",
    "        elif label == 4:\n",
    "            label = 6\n",
    "        elif label == 5:\n",
    "            label = 4\n",
    "        elif label == 6:\n",
    "            label = 0\n",
    "\n",
    "            \n",
    "        image = self.transform(image)\n",
    "        img1 = transforms.RandomHorizontalFlip(p=1.0)(image)\n",
    "        return image, label, idx, img1 \n",
    "\n",
    "    def get_labels(self):\n",
    "        label = self.label\n",
    "        return label\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, n_blocks, channels, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        \n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block=BasicBlock, n_blocks=[2,2,2,2], channels=[64, 128, 256, 512], stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n",
    "    \n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=7, drop_rate=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        res18 = ResNet(block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512], output_dim=1000)\n",
    "        msceleb_model = torch.load('../../checkpoint/resnet18_msceleb.pth')\n",
    "        state_dict = msceleb_model['state_dict']\n",
    "        res18.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])\n",
    "        self.features2 = nn.Sequential(*list(res18.children())[-2:-1])\n",
    "        \n",
    "        fc_in_dim = list(res18.children())[-1].in_features  # original fc layer's in dimention 512\n",
    "        self.fc = nn.Linear(fc_in_dim, num_classes)  # new fc layer 512x7\n",
    "        \n",
    "        self.parm={}\n",
    "        for name,parameters in self.fc.named_parameters():\n",
    "            print(name,':',parameters.size())\n",
    "            self.parm[name]=parameters\n",
    "        \n",
    "    def forward(self, x, clip_model):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        feat = x\n",
    "        ##N 512 7 7\n",
    "        x = self.features2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        fc_weights = self.parm['weight'].cuda()\n",
    "        fc_weights = fc_weights.view(1, 7, 512, 1, 1)\n",
    "        fc_weights = Variable(fc_weights, requires_grad = False)\n",
    "        feat = feat.unsqueeze(1) # N * 1 * C * H * W\n",
    "        hm = feat * fc_weights\n",
    "        hm = hm.sum(2) # N * self.num_labels * H * W\n",
    "        \n",
    "        out = self.fc(x)\n",
    "        return out, hm\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def add_g(image_array, mean=0.0, var=30):\n",
    "    std = var ** 0.5\n",
    "    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n",
    "    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n",
    "    return image_add\n",
    "\n",
    "def flip_image(image_array):\n",
    "    return cv2.flip(image_array, 1)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../../data/raf-basic', help='raf_dataset_path')\n",
    "parser.add_argument('--resnet50_path', type=str, default='../../data/resnet50_ft_weight.pkl', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "parser.add_argument('--w', type=int, default=7, help='width of the attention map')\n",
    "parser.add_argument('--h', type=int, default=7, help='height of the attention map')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='the number of the device')\n",
    "parser.add_argument('--lam', type=float, default=5, help='kl_lambda')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, optimizer, scheduler, device):\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    total_loss = []\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "    \n",
    "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        \n",
    "\n",
    "        output, hm1 = model(imgs1, clip_model)\n",
    "        \n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss1 \n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n",
    "    return acc, running_loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "setup_seed(3407)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.25)) ])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = RafDataset(phase='train', transform=train_transforms)\n",
    "test_dataset = RafDataset(phase='test', transform=eval_transforms)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model()\n",
    "device = torch.device('cuda:{}'.format(args.gpu))\n",
    "\n",
    "model.load_state_dict(torch.load(\"eac_FERPlus.pth\")['model_state_dict']) # mask baseline\n",
    "# model.load_state_dict(torch.load(\"result_logs/baseline_resnet18.pth\")['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "\n",
    "\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs, x = model(imgs1, clip_model)\n",
    "\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        data_num += outputs.size(0)\n",
    "\n",
    "    test_acc = correct_sum.float() / float(data_num)\n",
    "    print('test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170fea4",
   "metadata": {},
   "source": [
    "### MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00926c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : torch.Size([7, 512])\n",
      "bias : torch.Size([7])\n",
      "test acc:  tensor(0.5989, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import clip\n",
    "device = torch.device('cuda:0')\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, phase, transform=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        NAME_COLUMN = 0\n",
    "        LABEL_COLUMN = 1\n",
    "\n",
    "        dataset = pd.read_csv('../MMA_label.txt', sep=' ', header=None)\n",
    "\n",
    "        self.file_paths = dataset.iloc[:, NAME_COLUMN].values\n",
    "        self.label = dataset.iloc[:, LABEL_COLUMN].values\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = '../'+self.file_paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        img = image[:, :, ::-1]  # BGR to RGB\n",
    "\n",
    "        label = self.label[idx]\n",
    "        if label == 0:\n",
    "            label = 5\n",
    "        elif label == 1:\n",
    "            label = 2\n",
    "        elif label == 2:\n",
    "            label = 1\n",
    "        elif label == 3:\n",
    "            label = 3\n",
    "        elif label == 4:\n",
    "            label = 6\n",
    "        elif label == 5:\n",
    "            label = 4\n",
    "        elif label == 6:\n",
    "            label = 0\n",
    "\n",
    "            \n",
    "        image = self.transform(image)\n",
    "        img1 = transforms.RandomHorizontalFlip(p=1.0)(image)\n",
    "        return image, label, idx, img1 \n",
    "\n",
    "    def get_labels(self):\n",
    "        label = self.label\n",
    "        return label\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        i = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, n_blocks, channels, output_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        \n",
    "        self.in_channels = channels[0]\n",
    "            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        \n",
    "    def get_resnet_layer(self, block=BasicBlock, n_blocks=[2,2,2,2], channels=[64, 128, 256, 512], stride = 1):\n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        \n",
    "        return x, h\n",
    "    \n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=7, drop_rate=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        res18 = ResNet(block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512], output_dim=1000)\n",
    "        msceleb_model = torch.load('../../checkpoint/resnet18_msceleb.pth')\n",
    "        state_dict = msceleb_model['state_dict']\n",
    "        res18.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])\n",
    "        self.features2 = nn.Sequential(*list(res18.children())[-2:-1])\n",
    "        \n",
    "        fc_in_dim = list(res18.children())[-1].in_features  # original fc layer's in dimention 512\n",
    "        self.fc = nn.Linear(fc_in_dim, num_classes)  # new fc layer 512x7\n",
    "        \n",
    "        self.parm={}\n",
    "        for name,parameters in self.fc.named_parameters():\n",
    "            print(name,':',parameters.size())\n",
    "            self.parm[name]=parameters\n",
    "        \n",
    "    def forward(self, x, clip_model):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        feat = x\n",
    "        ##N 512 7 7\n",
    "        x = self.features2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        fc_weights = self.parm['weight'].cuda()\n",
    "        fc_weights = fc_weights.view(1, 7, 512, 1, 1)\n",
    "        fc_weights = Variable(fc_weights, requires_grad = False)\n",
    "        feat = feat.unsqueeze(1) # N * 1 * C * H * W\n",
    "        hm = feat * fc_weights\n",
    "        hm = hm.sum(2) # N * self.num_labels * H * W\n",
    "        \n",
    "        out = self.fc(x)\n",
    "        return out, hm\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def add_g(image_array, mean=0.0, var=30):\n",
    "    std = var ** 0.5\n",
    "    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n",
    "    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n",
    "    return image_add\n",
    "\n",
    "def flip_image(image_array):\n",
    "    return cv2.flip(image_array, 1)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raf_path', type=str, default='../../data/raf-basic', help='raf_dataset_path')\n",
    "parser.add_argument('--resnet50_path', type=str, default='../../data/resnet50_ft_weight.pkl', help='pretrained_backbone_path')\n",
    "parser.add_argument('--label_path', type=str, default='list_patition_label.txt', help='label_path')\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "parser.add_argument('--w', type=int, default=7, help='width of the attention map')\n",
    "parser.add_argument('--h', type=int, default=7, help='height of the attention map')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='the number of the device')\n",
    "parser.add_argument('--lam', type=float, default=5, help='kl_lambda')\n",
    "parser.add_argument('--epochs', type=int, default=60, help='number of epochs')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, optimizer, scheduler, device):\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    total_loss = []\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "    \n",
    "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        \n",
    "\n",
    "        output, hm1 = model(imgs1, clip_model)\n",
    "        \n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss1 \n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n",
    "    return acc, running_loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "setup_seed(3407)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.25)) ])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = RafDataset(phase='train', transform=train_transforms)\n",
    "test_dataset = RafDataset(phase='test', transform=eval_transforms)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=args.workers,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model()\n",
    "device = torch.device('cuda:{}'.format(args.gpu))\n",
    "# model.load_state_dict(torch.load(\"tmp_resnet18_mask_best.pth\")['model_state_dict'])\n",
    "# model.load_state_dict(torch.load(\"checkpoint/tmp_resnet18.pth\")['model_state_dict']) # mask baseline\n",
    "model.load_state_dict(torch.load(\"eac_FERPlus.pth\")['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct_sum = 0\n",
    "    data_num = 0\n",
    "\n",
    "\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs, x = model(imgs1, clip_model)\n",
    "\n",
    "        _, predicts = torch.max(outputs, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        data_num += outputs.size(0)\n",
    "\n",
    "    test_acc = correct_sum.float() / float(data_num)\n",
    "    print('test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adf447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
